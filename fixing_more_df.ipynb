{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import sqlite3\n",
    "from re import search\n",
    "import datetime\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = '/Users/jasleensandhu/Downloads/2005-19_Local_Authority_CO2_emissions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "avon_df = pd.read_csv('avon_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "avon_df.columns = ['index','Crime_ID', 'Month', 'Reported_by', 'Falls_within', 'Longitude', 'Latitude', \n",
    "                   'Location', 'LSOA_code', 'LSOA_name', 'Crime_type', 'Last_outcome_category', 'Context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "avon_df['Month'] = [i.year for i in pd.to_datetime(avon_df['Month'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove Nan Values\n",
    "avon_df = avon_df.dropna(subset=['LSOA_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-24e374c1e77e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  avon_df['lsoa_name'] = [i[:-5] for i in avon_df['LSOA_name']]\n"
     ]
    }
   ],
   "source": [
    "avon_df['lsoa_name'] = [i[:-5] for i in avon_df['LSOA_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bath and North East Somerset'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avon_df['LSOA_name'][4][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2 = pd.read_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2 = df_co2[df_co2['Region'] == 'South West']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2 = df_co2[['Local Authority', 'Calendar Year', \n",
    "                'LA CO2 Sector', 'Territorial emissions (kt CO2)', 'Mid-year Population (thousands)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2 = df_co2[2014 <= df_co2['Calendar Year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the C02 onto avon\n",
    "mapped = avon_df[avon_df['lsoa_name'].isin(df_co2['Local Authority'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the lengths to the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lst of Local authorities\n",
    "las = df_co2['Local Authority'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pollution = [sum(df_co2.loc[(df_co2['Calendar Year'] == i)]['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "bath_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Bath and North East Somerset')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pollution\n",
    "\n",
    "bath_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Bath and North East Somerset')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "bris_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Bristol, City of')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "north_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'North Somerset')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "south_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'South Gloucestershire')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "plymouth_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Plymouth')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "torbay_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Torbay')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "swid_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Swindon')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "corn_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Cornwall')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "isle_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Isles of Scilly')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "wilt_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Wiltshire')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "\n",
    "# bourn_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Bath and North East Somerset')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "chirch_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Bournemouth, Christchurch and Poole')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "dorse_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Dorset')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "east_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'East Devon')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "\n",
    "\n",
    "\n",
    "exter_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Exeter')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "mid_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Mid Devon')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "devon_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'North Devon')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "hams_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'South Hams')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "     \n",
    "tei_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Teignbridge')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "torrige_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Torridge')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "westdev_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'West Devon')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "chel_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Cheltenham')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "cot_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Cotswold')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "\n",
    "forrest_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Forest of Dean')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "glouc_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Gloucester')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "stroud_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Stroud')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "tewkesbury_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Tewkesbury')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "\n",
    "mendip_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Mendip')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "sedgemoor_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Sedgemoor')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "soutsomer_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'South Somerset')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "somer_taun_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Somerset West and Taunton')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollutions = [bath_pol, bris_pol, north_pol, south_pol, plymouth_pol, torbay_pol, swid_pol, corn_pol, isle_pol, wilt_pol,\n",
    "             chirch_pol, dorse_pol, east_pol, exter_pol, mid_pol, devon_pol, hams_pol, tei_pol, torrige_pol, westdev_pol, \n",
    "            chel_pol, cot_pol, forrest_pol, glouc_pol, stroud_pol, tewkesbury_pol, mendip_pol, sedgemoor_pol, soutsomer_pol,\n",
    "             somer_taun_pol]\n",
    "dictionary = dict(zip(las, pollutions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "## population\n",
    "\n",
    "bath_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Bath and North East Somerset')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "bris_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Bristol, City of')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "north_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'North Somerset')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "south_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'South Gloucestershire')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "plymouth_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Plymouth')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "torbay_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Torbay')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "swid_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Swindon')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "corn_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Cornwall')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "isle_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Isles of Scilly')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "wilt_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Wiltshire')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "\n",
    "# bourn_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Bath and North East Somerset')])['Territorial emissions (kt CO2)']) for i in range(2014, 2020)]\n",
    "chirch_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Bournemouth, Christchurch and Poole')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "dorse_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Dorset')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "east_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'East Devon')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "\n",
    "exter_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Exeter')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "mid_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Mid Devon')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "devon_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'North Devon')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "hams_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'South Hams')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "     \n",
    "tei_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Teignbridge')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "torrige_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Torridge')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "westdev_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'West Devon')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "chel_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Cheltenham')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "cot_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Cotswold')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "\n",
    "forrest_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Forest of Dean')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "glouc_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Gloucester')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "stroud_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Stroud')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "tewkesbury_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Tewkesbury')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "\n",
    "mendip_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Mendip')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "sedgemoor_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Sedgemoor')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "soutsomer_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'South Somerset')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n",
    "somer_taun_pol = [sum((df_co2.loc[(df_co2['Calendar Year'] == i) & (df_co2['Local Authority'] == 'Somerset West and Taunton')])['Mid-year Population (thousands)']) for i in range(2014, 2020)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = [bath_pol, bris_pol, north_pol, south_pol, plymouth_pol, torbay_pol, swid_pol, corn_pol, isle_pol, wilt_pol,\n",
    "             chirch_pol, dorse_pol, east_pol, exter_pol, mid_pol, devon_pol, hams_pol, tei_pol, torrige_pol, westdev_pol, \n",
    "            chel_pol, cot_pol, forrest_pol, glouc_pol, stroud_pol, tewkesbury_pol, mendip_pol, sedgemoor_pol, soutsomer_pol,\n",
    "             somer_taun_pol]\n",
    "dictionary = dict(zip(las, population))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = avon_df.loc[avon_df['Month'] == 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_2014 = df_co2.loc[df_co2['Calendar Year'] == 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pollution_dates(region, year):\n",
    "    dataframe_year =  mapped.loc[mapped['Month'] == year]\n",
    "    df_region = dataframe_year.loc[dataframe_year['lsoa_name'] == region]\n",
    "    \n",
    "    if year == 2014:\n",
    "        df_region['pollution'] = dictionary[region][0]\n",
    "    elif year == 2015:\n",
    "        df_region['pollution'] = dictionary[region][1]\n",
    "    elif year == 2016:\n",
    "        df_region['pollution'] = dictionary[region][2]\n",
    "    elif year == 2017:\n",
    "        df_region['pollution'] = dictionary[region][3]\n",
    "    elif year == 2018:\n",
    "        df_region['pollution'] = dictionary[region][4]\n",
    "    else:\n",
    "        df_region['pollution'] = dictionary[region][5]\n",
    "        \n",
    "    return df_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_dates(region, year):\n",
    "    dataframe_year =  mapped.loc[mapped['Month'] == year]\n",
    "    df_region = dataframe_year.loc[dataframe_year['lsoa_name'] == region]\n",
    "    \n",
    "    if year == 2014:\n",
    "        df_region['population'] = dictionary[region][0]\n",
    "    elif year == 2015:\n",
    "        df_region['population'] = dictionary[region][1]\n",
    "    elif year == 2016:\n",
    "        df_region['population'] = dictionary[region][2]\n",
    "    elif year == 2017:\n",
    "        df_region['population'] = dictionary[region][3]\n",
    "    elif year == 2018:\n",
    "        df_region['population'] = dictionary[region][4]\n",
    "    else:\n",
    "        df_region['population'] = dictionary[region][5]\n",
    "        \n",
    "    return df_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-b6e68dc4a827>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_region['pollution'] = dictionary[region][0]\n",
      "<ipython-input-86-b6e68dc4a827>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_region['pollution'] = dictionary[region][1]\n",
      "<ipython-input-86-b6e68dc4a827>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_region['pollution'] = dictionary[region][2]\n",
      "<ipython-input-86-b6e68dc4a827>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_region['pollution'] = dictionary[region][3]\n",
      "<ipython-input-86-b6e68dc4a827>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_region['pollution'] = dictionary[region][4]\n",
      "<ipython-input-86-b6e68dc4a827>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_region['pollution'] = dictionary[region][5]\n"
     ]
    }
   ],
   "source": [
    "## pollution\n",
    "\n",
    "bath = [(pollution_dates('Bath and North East Somerset', i)) for i in range(2014, 2020)]\n",
    "bristol = [(pollution_dates('Bristol, City of', i)) for i in range(2014, 2020)]\n",
    "north_som = [(pollution_dates('North Somerset', i)) for i in range(2014, 2020)] \n",
    "\n",
    "south_glou = [(pollution_dates('South Gloucestershire', i)) for i in range(2014, 2020)]\n",
    "ply = [(pollution_dates('Plymouth', i)) for i in range(2014, 2020)]\n",
    "torbay = [(pollution_dates('Torbay', i)) for i in range(2014, 2020)] \n",
    "\n",
    "swindon = [(pollution_dates('Swindon', i)) for i in range(2014, 2020)]\n",
    "cornwal = [(pollution_dates('Cornwall', i)) for i in range(2014, 2020)]\n",
    "isle = [(pollution_dates('Isles of Scilly', i)) for i in range(2014, 2020)] \n",
    "\n",
    "wilt = [(pollution_dates('Wiltshire', i)) for i in range(2014, 2020)]\n",
    "bouhem = [(pollution_dates('Bournemouth, Christchurch and Poole', i)) for i in range(2014, 2020)]\n",
    "dorse = [(pollution_dates('Dorset', i)) for i in range(2014, 2020)] \n",
    "\n",
    "east_dev = [(pollution_dates('East Devon', i)) for i in range(2014, 2020)]\n",
    "exeter = [(pollution_dates('Exeter', i)) for i in range(2014, 2020)]\n",
    "mid = [(pollution_dates('Mid Devon', i)) for i in range(2014, 2020)] \n",
    "\n",
    "north_dev = [(pollution_dates('North Devon', i)) for i in range(2014, 2020)]\n",
    "south_ham = [(pollution_dates('South Hams', i)) for i in range(2014, 2020)]\n",
    "teign = [(pollution_dates('Teignbridge', i)) for i in range(2014, 2020)] \n",
    "\n",
    "torr = [(pollution_dates('Torridge', i)) for i in range(2014, 2020)]\n",
    "west_dev = [(pollution_dates('West Devon', i)) for i in range(2014, 2020)]\n",
    "chelten = [(pollution_dates('Cheltenham', i)) for i in range(2014, 2020)] \n",
    "\n",
    "cotsw = [(pollution_dates('Cotswold', i)) for i in range(2014, 2020)]\n",
    "forest = [(pollution_dates('Forest of Dean', i)) for i in range(2014, 2020)]\n",
    "gloucester = [(pollution_dates('Gloucester', i)) for i in range(2014, 2020)] \n",
    "\n",
    "stroud = [(pollution_dates('Stroud', i)) for i in range(2014, 2020)]\n",
    "tewkes = [(pollution_dates('Tewkesbury', i)) for i in range(2014, 2020)]\n",
    "mendip = [(pollution_dates('Mendip', i)) for i in range(2014, 2020)]\n",
    "\n",
    "sedgem = [(pollution_dates('Sedgemoor', i)) for i in range(2014, 2020)]\n",
    "south_somer = [(pollution_dates('South Somerset', i)) for i in range(2014, 2020)]\n",
    "somerset_west = [(pollution_dates('Somerset West and Taunton', i)) for i in range(2014, 2020)] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-199-599438bb6a23>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_region['population'] = dictionary[region][0]\n",
      "<ipython-input-199-599438bb6a23>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_region['population'] = dictionary[region][1]\n",
      "<ipython-input-199-599438bb6a23>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_region['population'] = dictionary[region][2]\n",
      "<ipython-input-199-599438bb6a23>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_region['population'] = dictionary[region][3]\n",
      "<ipython-input-199-599438bb6a23>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_region['population'] = dictionary[region][4]\n",
      "<ipython-input-199-599438bb6a23>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_region['population'] = dictionary[region][5]\n"
     ]
    }
   ],
   "source": [
    "## population\n",
    "## pollution\n",
    "\n",
    "bath = [(population_dates('Bath and North East Somerset', i)) for i in range(2014, 2020)]\n",
    "bristol = [(population_dates('Bristol, City of', i)) for i in range(2014, 2020)]\n",
    "north_som = [(population_dates('North Somerset', i)) for i in range(2014, 2020)] \n",
    "\n",
    "south_glou = [(population_dates('South Gloucestershire', i)) for i in range(2014, 2020)]\n",
    "ply = [(population_dates('Plymouth', i)) for i in range(2014, 2020)]\n",
    "torbay = [(population_dates('Torbay', i)) for i in range(2014, 2020)] \n",
    "\n",
    "swindon = [(population_dates('Swindon', i)) for i in range(2014, 2020)]\n",
    "cornwal = [(population_dates('Cornwall', i)) for i in range(2014, 2020)]\n",
    "isle = [(population_dates('Isles of Scilly', i)) for i in range(2014, 2020)] \n",
    "\n",
    "wilt = [(population_dates('Wiltshire', i)) for i in range(2014, 2020)]\n",
    "bouhem = [(population_dates('Bournemouth, Christchurch and Poole', i)) for i in range(2014, 2020)]\n",
    "dorse = [(population_dates('Dorset', i)) for i in range(2014, 2020)] \n",
    "\n",
    "east_dev = [(population_dates('East Devon', i)) for i in range(2014, 2020)]\n",
    "exeter = [(population_dates('Exeter', i)) for i in range(2014, 2020)]\n",
    "mid = [(population_dates('Mid Devon', i)) for i in range(2014, 2020)] \n",
    "\n",
    "north_dev = [(population_dates('North Devon', i)) for i in range(2014, 2020)]\n",
    "south_ham = [(population_dates('South Hams', i)) for i in range(2014, 2020)]\n",
    "teign = [(population_dates('Teignbridge', i)) for i in range(2014, 2020)] \n",
    "\n",
    "torr = [(population_dates('Torridge', i)) for i in range(2014, 2020)]\n",
    "west_dev = [(population_dates('West Devon', i)) for i in range(2014, 2020)]\n",
    "chelten = [(population_dates('Cheltenham', i)) for i in range(2014, 2020)] \n",
    "\n",
    "cotsw = [(population_dates('Cotswold', i)) for i in range(2014, 2020)]\n",
    "forest = [(population_dates('Forest of Dean', i)) for i in range(2014, 2020)]\n",
    "gloucester = [(population_dates('Gloucester', i)) for i in range(2014, 2020)] \n",
    "\n",
    "stroud = [(population_dates('Stroud', i)) for i in range(2014, 2020)]\n",
    "tewkes = [(population_dates('Tewkesbury', i)) for i in range(2014, 2020)]\n",
    "mendip = [(population_dates('Mendip', i)) for i in range(2014, 2020)]\n",
    "\n",
    "sedgem = [(population_dates('Sedgemoor', i)) for i in range(2014, 2020)]\n",
    "south_somer = [(population_dates('South Somerset', i)) for i in range(2014, 2020)]\n",
    "somerset_west = [(population_dates('Somerset West and Taunton', i)) for i in range(2014, 2020)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(set(mapped['lsoa_name'].unique()) - set(avon_df['lsoa_name'].unique()))\n",
    "\n",
    "lst_pdf = [bath, bristol, north_som, south_glou, ply, torbay, swindon, cornwal, isle,\n",
    "wilt, bouhem, dorse, east_dev, exeter, mid, north_dev, south_ham, teign,\n",
    "torr, west_dev, chelten, cotsw, forest, gloucester, stroud, tewkes,\n",
    "mendip, sedgem, south_somer, somerset_west]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollution = pd.concat([pd.concat(i) for i in lst_pdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_pdf = [bath, bristol, north_som, south_glou, ply, torbay, swindon, cornwal, isle,\n",
    "wilt, bouhem, dorse, east_dev, exeter, mid, north_dev, south_ham, teign,\n",
    "torr, west_dev, chelten, cotsw, forest, gloucester, stroud, tewkes,\n",
    "mendip, sedgem, south_somer, somerset_west]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.concat([pd.concat(i) for i in lst_pdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (bbb)\n",
    "# (pd.concat(bbb))\n",
    "pollution['population'] = population['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Send data to csv to merge with other dataframes\n",
    "\n",
    "pollution.to_csv('pollution_merged.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads = pd.read_csv('roads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('merged_pol_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "roads_df = roads[roads['lsoa_of_accident_location'].isin(final['LSOA_code'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep only needed lsoas\n",
    "# for elements in lst1 keep only if in lst2\n",
    "\n",
    "codes = [value for value in roads_df['lsoa_of_accident_location'].values if value in final['LSOA_code'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_df = roads[roads['lsoa_of_accident_location'].isin(codes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_final = final[final['LSOA_code'].isin(roads_df['lsoa_of_accident_location'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-293-d7714660ff43>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  roads_df['LSOA_code'] = roads_df['lsoa_of_accident_location']\n"
     ]
    }
   ],
   "source": [
    "# sort based on final\n",
    "\n",
    "roads_df['LSOA_code'] = roads_df['lsoa_of_accident_location']\n",
    "\n",
    "# pd.Categorical(\n",
    "#     roads_df['lsoa_of_accident_location'], \n",
    "#     categories=road_final['LSOA_code'].unique(), \n",
    "#     ordered=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge\n",
    "## years\n",
    "lst_2020 = []\n",
    "lst_2019 = []\n",
    "lst_2018 = []\n",
    "\n",
    "lst_2017 = []\n",
    "lst_2016 = []\n",
    "lst_2015 = []\n",
    "\n",
    "lst_2014 = []\n",
    "lst_2013 = []\n",
    "lst_2012 = []\n",
    "\n",
    "lst_2010 = []\n",
    "lst_20 = []\n",
    "\n",
    "\n",
    "for i in range(0, len(roads_df)):\n",
    "    if roads_df['accident_year'].iloc[i] == 2020:\n",
    "        lst_2020.append(roads_df.iloc[i])\n",
    "        \n",
    "    elif roads_df['accident_year'].iloc[i] == 2019:\n",
    "        lst_2019.append(roads_df.iloc[i])\n",
    "    \n",
    "    elif roads_df['accident_year'].iloc[i] == 2018:\n",
    "        lst_2018.append(roads_df.iloc[i])\n",
    "    \n",
    "    elif roads_df['accident_year'].iloc[i] == 2017:\n",
    "        lst_2017.append(roads_df.iloc[i])\n",
    "        \n",
    "    elif roads_df['accident_year'].iloc[i] == 2016:\n",
    "        lst_2016.append(roads_df.iloc[i])\n",
    "        \n",
    "    elif roads_df['accident_year'].iloc[i] == 2015:\n",
    "        lst_2015.append(roads_df.iloc[i])\n",
    "        \n",
    "    elif roads_df['accident_year'].iloc[i] == 2014:\n",
    "        lst_2014.append(roads_df.iloc[i])\n",
    "        \n",
    "    elif roads_df['accident_year'].iloc[i] == 2013:\n",
    "        lst_2013.append(roads_df.iloc[i])\n",
    "        \n",
    "    elif roads_df['accident_year'].iloc[i] == 2012:\n",
    "        lst_2020.append(roads_df.iloc[i])\n",
    "        \n",
    "    elif roads_df['accident_year'].iloc[i] == 2010:\n",
    "        lst_2012.append(roads_df.iloc[i])\n",
    "        \n",
    "    else:\n",
    "        lst_20.append('none')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_lst = lst_2020 + lst_2018 + lst_2017 + lst_2016 + lst_2015 + lst_2014 + lst_2013 + lst_2012 +lst_2010 + lst_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_2020 = (pd.DataFrame(lst_2020)).merge(final, on='LSOA_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv('df_income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = income.drop(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
    "                     '13', '14'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_region = income.iloc[8] ## corresponds to our region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_lst = []\n",
    "\n",
    "for i in final['year']:\n",
    "    if i == 2010:\n",
    "        income_lst.append(west_region[2])\n",
    "    elif i == 2012:\n",
    "        income_lst.append(west_region[3])\n",
    "    elif i == 2013:\n",
    "        income_lst.append(west_region[4])\n",
    "    elif i == 2015:\n",
    "        income_lst.append(west_region[5])\n",
    "        \n",
    "    elif i == 2016:\n",
    "        income_lst.append(west_region[6])\n",
    "        \n",
    "    elif i == 2017:\n",
    "        income_lst.append(west_region[7])\n",
    "        \n",
    "    elif i == 2018:\n",
    "        income_lst.append(west_region[8])\n",
    "        \n",
    "    elif i == 2019:\n",
    "        income_lst.append(west_region[9])\n",
    "        \n",
    "    elif i == 2020:\n",
    "        income_lst.append(west_region[10])\n",
    "    else:\n",
    "        income_lst.append('none')\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['income'] = income_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final.groupby('class').sum('without') ## this doesnt work because there are values missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_grouped = final.groupby(['class']).mean(['without', 'gcse', 'gcs_a', 'degree', 'income', 'pollution', 'population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Lasso(alpha=1.0)\n",
    "\n",
    "X = final_grouped[['pollution', 'population']]\n",
    "y = final['class'].value_counts()\n",
    "\n",
    "cv = RepeatedKFold(n_splits=50, n_repeats=10, random_state=8)\n",
    "scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "\n",
    "# final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 2100.084 (5009.732)\n"
     ]
    }
   ],
   "source": [
    "scores = absolute(scores)\n",
    "\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores)/57, std(scores)/56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA_code</th>\n",
       "      <th>pollution</th>\n",
       "      <th>population</th>\n",
       "      <th>index</th>\n",
       "      <th>Crime_ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Reported_by</th>\n",
       "      <th>Falls_within</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>LSOA_name</th>\n",
       "      <th>Crime_type</th>\n",
       "      <th>Last_outcome_category</th>\n",
       "      <th>Context</th>\n",
       "      <th>lang_lat</th>\n",
       "      <th>class</th>\n",
       "      <th>year</th>\n",
       "      <th>without</th>\n",
       "      <th>gcse</th>\n",
       "      <th>gcs_a</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E01014399</td>\n",
       "      <td>790.852231</td>\n",
       "      <td>3987.302</td>\n",
       "      <td>0</td>\n",
       "      <td>40fc4a22e7380425d00baa79a7de8f8951b7baef0f7b4d...</td>\n",
       "      <td>2014-06</td>\n",
       "      <td>Avon and Somerset Constabulary</td>\n",
       "      <td>Avon and Somerset Constabulary</td>\n",
       "      <td>-2.511761</td>\n",
       "      <td>51.409966</td>\n",
       "      <td>On or near Caernarvon Close</td>\n",
       "      <td>Bath and North East Somerset 001A</td>\n",
       "      <td>Criminal damage and arson</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>164206</td>\n",
       "      <td>715652</td>\n",
       "      <td>758353</td>\n",
       "      <td>743661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E01014399</td>\n",
       "      <td>790.852231</td>\n",
       "      <td>3987.302</td>\n",
       "      <td>1</td>\n",
       "      <td>c70c58a712c27d96fa3ab350afa79c67eae3a6cc37f262...</td>\n",
       "      <td>2014-06</td>\n",
       "      <td>Avon and Somerset Constabulary</td>\n",
       "      <td>Avon and Somerset Constabulary</td>\n",
       "      <td>-2.515816</td>\n",
       "      <td>51.408717</td>\n",
       "      <td>On or near Caroline Close</td>\n",
       "      <td>Bath and North East Somerset 001A</td>\n",
       "      <td>Vehicle crime</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>164206</td>\n",
       "      <td>715652</td>\n",
       "      <td>758353</td>\n",
       "      <td>743661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E01014399</td>\n",
       "      <td>790.852231</td>\n",
       "      <td>3987.302</td>\n",
       "      <td>2</td>\n",
       "      <td>042553d9545f4f15c8811ca2461f7db218120b44e5bf61...</td>\n",
       "      <td>2014-06</td>\n",
       "      <td>Avon and Somerset Constabulary</td>\n",
       "      <td>Avon and Somerset Constabulary</td>\n",
       "      <td>-2.515816</td>\n",
       "      <td>51.408717</td>\n",
       "      <td>On or near Caroline Close</td>\n",
       "      <td>Bath and North East Somerset 001A</td>\n",
       "      <td>Vehicle crime</td>\n",
       "      <td>Investigation complete; no suspect identified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>164206</td>\n",
       "      <td>715652</td>\n",
       "      <td>758353</td>\n",
       "      <td>743661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LSOA_code   pollution  population  index  \\\n",
       "0  E01014399  790.852231    3987.302      0   \n",
       "1  E01014399  790.852231    3987.302      1   \n",
       "2  E01014399  790.852231    3987.302      2   \n",
       "\n",
       "                                            Crime_ID    Month  \\\n",
       "0  40fc4a22e7380425d00baa79a7de8f8951b7baef0f7b4d...  2014-06   \n",
       "1  c70c58a712c27d96fa3ab350afa79c67eae3a6cc37f262...  2014-06   \n",
       "2  042553d9545f4f15c8811ca2461f7db218120b44e5bf61...  2014-06   \n",
       "\n",
       "                      Reported_by                    Falls_within  Longitude  \\\n",
       "0  Avon and Somerset Constabulary  Avon and Somerset Constabulary  -2.511761   \n",
       "1  Avon and Somerset Constabulary  Avon and Somerset Constabulary  -2.515816   \n",
       "2  Avon and Somerset Constabulary  Avon and Somerset Constabulary  -2.515816   \n",
       "\n",
       "    Latitude                     Location                          LSOA_name  \\\n",
       "0  51.409966  On or near Caernarvon Close  Bath and North East Somerset 001A   \n",
       "1  51.408717    On or near Caroline Close  Bath and North East Somerset 001A   \n",
       "2  51.408717    On or near Caroline Close  Bath and North East Somerset 001A   \n",
       "\n",
       "                  Crime_type                          Last_outcome_category  \\\n",
       "0  Criminal damage and arson  Investigation complete; no suspect identified   \n",
       "1              Vehicle crime  Investigation complete; no suspect identified   \n",
       "2              Vehicle crime  Investigation complete; no suspect identified   \n",
       "\n",
       "   Context lang_lat  class  year without    gcse   gcs_a  degree  \n",
       "0      NaN     long      1  2014  164206  715652  758353  743661  \n",
       "1      NaN     long      1  2014  164206  715652  758353  743661  \n",
       "2      NaN     long      1  2014  164206  715652  758353  743661  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# load the dataset\n",
    "data = dataframe.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# define model\n",
    "model = Lasso(alpha=1.0)\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-79-b5ab836848c9>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dunno['pollution']  = dictionary['Bath and North East Somerset'][0]\n"
     ]
    }
   ],
   "source": [
    "dunno = df_2014.loc[df_2014['lsoa_name'] == 'Bath and North East Somerset']\n",
    "dunno['pollution']  = dictionary['Bath and North East Somerset'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-105-9b0cbc156025>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dunno_1['pollution']  = dictionary['Bath and North East Somerset'][1]\n"
     ]
    }
   ],
   "source": [
    "df_2015 = avon_df.loc[avon_df['Month'] == 2015]\n",
    "dunno_1 = df_2015.loc[df_2015['lsoa_name'] == 'Bath and North East Somerset']\n",
    "dunno_1['pollution']  = dictionary['Bath and North East Somerset'][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
