{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import geopy.distance\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DataFrameWithClusterLabels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing avon df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "avon_df = pd.read_csv('avon_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "avon_df.columns = ['index','Crime_ID', 'Month', 'Reported_by', 'Falls_within', 'Longitude', 'Latitude', \n",
    "                   'Location', 'LSOA_code', 'LSOA_name', 'Crime_type', 'Last_outcome_category', 'Context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avon_df = avon_df.dropna(subset=['Longitude', 'Latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decimal\n",
    "def drange(x, y, jump):\n",
    "    while x < y:\n",
    "        yield float(x)\n",
    "        x += decimal.Decimal(jump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range of coords from avon\n",
    "# sorted(avon_df['Longitude'].unique())[0]\n",
    "# sorted(avon_df['Longitude'].unique())[-1]\n",
    "\n",
    "# sorted(df['Longitude'].unique())[0]\n",
    "# sorted(df['Latitude'].unique())[-1] # range of these values dont change\n",
    "\n",
    "# Construct\n",
    "long = (avon_df['Longitude'].unique())\n",
    "lat = (avon_df['Latitude'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to clusters\n",
    "clusters_long = df['Longitude'].unique()\n",
    "clusters_lat = df['Latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_long = [value for value in long if value in clusters_long]\n",
    "intersect_lat = [value for value in lat if value in clusters_lat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "both = list(zip(intersect_long, intersect_lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_avon = avon_df[avon_df['Longitude'].isin(intersect_long)]\n",
    "lat_avon = avon_df[avon_df['Latitude'].isin(intersect_lat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overlap the dataframes and remove any repitive rows\n",
    "## fitted for avon\n",
    "final_df = pd.concat([long_avon, lat_avon]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter with long and lat\n",
    "avon_long = final_df[final_df['Longitude'].isin(clusters_long)]\n",
    "avon_lat = final_df[final_df['Latitude'].isin(clusters_lat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.concat([avon_long, avon_lat]).drop_duplicates()\n",
    "#pd.concat([clusters_long, clusters_lat]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_lat_lst = []\n",
    "for i in clusters['Longitude']:\n",
    "    if i in intersect_long:\n",
    "        long_lat_lst.append('long')\n",
    "    else:\n",
    "        long_lat_lst.append('lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avon_long['coord_value'] = 'long'\n",
    "# avon_lat['coord_value'] = 'lat'\n",
    "\n",
    "clusters['lang_lat'] = long_lat_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort list based on another\n",
    "\n",
    "result_list_long = [i for _,i in (zip(clusters['Longitude'],df['labels']))][:1476564]\n",
    "result_list_lat = [i for _,i in (zip(clusters['Latitude'],df['labels']))][:116451]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## making seperate long and lats map to labels\n",
    "long_df = df[df['Longitude'].isin(intersect_long)]\n",
    "lat_df = df[df['Latitude'].isin(intersect_lat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_df = (df[df['Longitude'].isin(result_list_long)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete = pd.concat([long_df, lat_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters['class'] = result_list_long + result_list_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## opening the pollution dataframe\n",
    "pollution = pd.read_csv('pollution_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removal of uncessary rows\n",
    "new_pollution = pollution[~pollution['LSOA_code'].isin(clusters['LSOA_code'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = clusters[clusters['LSOA_code'].isin(pollution['LSOA_code'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mer = merged[['LSOA_code']]\n",
    "poll = pollution[['LSOA_code', 'pollution', 'population']]\n",
    "\n",
    "mer_class = (mer[mer['LSOA_code'].isin(poll['LSOA_code'].values)])\n",
    "# poll_class = (poll[poll['LSOA_code'].isin(merged['LSOA_code'].values)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll = (pd.concat([mer_class, poll_class])).dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(merged['LSOA_code'])\n",
    "\n",
    "final = pd.merge(poll, merged, on='LSOA_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "(final).to_csv('merged_pol.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['year'] = [i.year for i in pd.to_datetime(final['Month'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "education = pd.read_csv('south_west_education.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "without = []\n",
    "gcse = []\n",
    "gcs_a = []\n",
    "degree = []\n",
    "\n",
    "\n",
    "for i in final['year']:\n",
    "    if i == 2014:\n",
    "        without.append(education['Jan 2014-Dec 2014'][0])\n",
    "        gcse.append(education['Jan 2014-Dec 2014'][1])\n",
    "        gcs_a.append(education['Jan 2014-Dec 2014'][2])\n",
    "        degree.append(education['Jan 2014-Dec 2014'][3])\n",
    "    elif i == 2015:\n",
    "        without.append(education['Jan 2015-Dec 2015'][0])\n",
    "        gcse.append(education['Jan 2015-Dec 2015'][1])\n",
    "        gcs_a.append(education['Jan 2015-Dec 2015'][2])\n",
    "        degree.append(education['Jan 2015-Dec 2015'][3])\n",
    "    elif i == 2016:\n",
    "        without.append(education['Jan 2016-Dec 2016'][0])\n",
    "        gcse.append(education['Jan 2016-Dec 2016'][1])\n",
    "        gcs_a.append(education['Jan 2016-Dec 2016'][2])\n",
    "        degree.append(education['Jan 2016-Dec 2016'][3])\n",
    "    elif i == 2017:\n",
    "        without.append(education['Jan 2017-Dec 2017'][0])\n",
    "        gcse.append(education['Jan 2017-Dec 2017'][1])\n",
    "        gcs_a.append(education['Jan 2017-Dec 2017'][2])\n",
    "        degree.append(education['Jan 2017-Dec 2017'][3])\n",
    "        \n",
    "    elif i == 2018:\n",
    "        without.append(education['Jan 2018-Dec 2018'][0])\n",
    "        gcse.append(education['Jan 2018-Dec 2018'][1])\n",
    "        gcs_a.append(education['Jan 2018-Dec 2018'][2])\n",
    "        degree.append(education['Jan 2018-Dec 2018'][3])\n",
    "        \n",
    "    else:\n",
    "        without.append('none')\n",
    "        gcse.append('none')\n",
    "        gcs_a.append('none')\n",
    "        degree.append('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['without'] = without\n",
    "final['gcse'] = gcse\n",
    "final['gcs_a'] = gcs_a\n",
    "final['degree'] = degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "(final).to_csv('merged_pol_2.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run based on pollution dataframe, by taking subset and \n",
    "# cluster_pollution = pd.merge(clusters, pollution, on='LSOA_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(avon_df[['Crime_type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learnt from the models as well as analysed; how can this allow us to make better tools in the future?\n",
    "## these are the key finidngs and the stuff we can do with we know\n",
    "\n",
    "## Use regression to predict the type of crime and the location? \n",
    "## The outcomes from this means that they can analyse these features in time to see how with time when this changes also\n",
    "## the crime will relate and the types of crimes will also be similar and will be commited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Spatial Regression - Convert longitdude and latidue into a degree (value), \n",
    "## Converting into the degrees in itself has limitations\n",
    "## talk about feature engineering the distance\n",
    "# macro-economic factors, technology, globalization, work and lifestyle choices, the organization of crime, and criminal justice resources and responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279.35290160430094\n"
     ]
    }
   ],
   "source": [
    "coords_1 = (52.2296756, 21.0122287)\n",
    "coords_2 = (52.406374, 16.9251681)\n",
    "\n",
    "print(geopy.distance.geodesic(coords_1, coords_2).km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2019-06-01\n",
       "1         2019-01-01\n",
       "2         2011-10-01\n",
       "3         2019-05-01\n",
       "4         2021-03-01\n",
       "             ...    \n",
       "1580217   2020-09-01\n",
       "1580218   2011-06-01\n",
       "1580221   2021-09-01\n",
       "1580223   2017-09-01\n",
       "1580224   2018-07-01\n",
       "Name: Month, Length: 827344, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(cluster_1['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression Analysis\n",
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_lat = (list(zip(avon_df['Longitude'], avon_df['Latitude'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_long_lat = (pd.Series(long_lat).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converts the Lat and Long of Avon coords, needed to filter DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(unique_long_lat).to_csv('unique_long_lat.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1843836"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
